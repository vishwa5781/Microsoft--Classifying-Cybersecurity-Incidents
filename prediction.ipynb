{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(f'dataset\\GUIDE_Test\\GUIDE_Test.csv',low_memory=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'MitreTechniques' has 55.56% missing values.\n",
      "Column 'ActionGrouped' has 99.95% missing values.\n",
      "Column 'ActionGranular' has 99.95% missing values.\n",
      "Column 'EmailClusterId' has 98.99% missing values.\n",
      "Column 'ThreatFamily' has 99.25% missing values.\n",
      "Column 'ResourceType' has 99.93% missing values.\n",
      "Column 'Roles' has 97.36% missing values.\n",
      "Column 'AntispamDirection' has 98.15% missing values.\n",
      "Column 'SuspicionLevel' has 84.37% missing values.\n",
      "Column 'LastVerdict' has 76.09% missing values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18196\\2916278563.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  space_only_count = (df1.applymap(lambda x: isinstance(x, str) and x.isspace())).mean()\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df1, threshold_percentage=0.2):\n",
    "    columns_to_drop = set()\n",
    "\n",
    "    nan_counts = df1.isnull().mean()\n",
    "    nan_columns = nan_counts[nan_counts > threshold_percentage]\n",
    "    for col, percent in nan_columns.items():\n",
    "        print(f\"Column '{col}' has {percent:.2%} missing values.\")\n",
    "        columns_to_drop.add(col)\n",
    "\n",
    "    empty_str_count = (df1 == '').mean()\n",
    "    empty_str_columns = empty_str_count[empty_str_count > threshold_percentage]\n",
    "    for col, percent in empty_str_columns.items():\n",
    "        print(f\"Column '{col}' has {percent:.2%} empty string values.\")\n",
    "        columns_to_drop.add(col)\n",
    "\n",
    "    space_only_count = (df1.applymap(lambda x: isinstance(x, str) and x.isspace())).mean()\n",
    "    space_only_columns = space_only_count[space_only_count > threshold_percentage]\n",
    "    for col, percent in space_only_columns.items():\n",
    "        print(f\"Column '{col}' has {percent:.2%} space-only values.\")\n",
    "        columns_to_drop.add(col)\n",
    "\n",
    "    problematic_values = ['N/A', 'NA', 'null', 'NULL']\n",
    "    for value in problematic_values:\n",
    "        problematic_count = (df1 == value).mean()\n",
    "        problematic_columns = problematic_count[problematic_count > threshold_percentage]\n",
    "        for col, percent in problematic_columns.items():\n",
    "            print(f\"Column '{col}' has {percent:.2%} '{value}' values.\")\n",
    "            columns_to_drop.add(col)\n",
    "\n",
    "    return df1\n",
    "result = check_missing_values(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LastVerdict']=df['LastVerdict'].fillna('No Verdict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((df['LastVerdict'] == 'DomainPII_50d8b4a941c26b89482c94ab324b5a274f9ced66').sum())\n",
    "print((df['LastVerdict'] == 'DomainPII_9207384283ce115db5a590dd9ca5de21e5e99df2').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Usage','ActionGrouped','ActionGranular','EmailClusterId','ThreatFamily','AntispamDirection','SuspicionLevel','Roles','ResourceType'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Timestamp','MitreTechniques'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LateralMovement', 'CommandAndControl', 'InitialAccess',\n",
       "       'Discovery', 'SuspiciousActivity', 'Impact', 'CredentialAccess',\n",
       "       'Exfiltration', 'UnwantedSoftware', 'DefenseEvasion', 'Malware',\n",
       "       'Execution', 'Persistence', 'CredentialStealing', 'Collection',\n",
       "       'Ransomware', 'Exploit', 'PrivilegeEscalation', 'WebExploit'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User' 'Machine' 'Process' 'CloudLogonSession' 'Ip' 'File' 'MailMessage'\n",
      " 'CloudLogonRequest' 'Url' 'CloudApplication' 'MailCluster' 'Mailbox'\n",
      " 'RegistryValue' 'AzureResource' 'GenericEntity' 'Malware' 'RegistryKey'\n",
      " 'OAuthApplication' 'Blob' 'MailboxConfiguration' 'SecurityGroup'\n",
      " 'BlobContainer' 'ActiveDirectoryDomain' 'Nic' 'IoTDevice']\n"
     ]
    }
   ],
   "source": [
    "print(df['EntityType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Impacted', 'Related'], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EvidenceRole'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Suspicious', 'No Verdict', 'Malicious', 'NoThreatsFound',\n",
       "       'DomainPII_50d8b4a941c26b89482c94ab324b5a274f9ced66'], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LastVerdict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_verdicts = ['No Verdict', 'Suspicious', 'Malicious', 'NoThreatsFound']\n",
    "df = df[df['LastVerdict'].isin(valid_verdicts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['Category', 'EntityType', 'EvidenceRole', 'LastVerdict', 'IncidentGrade']\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    label_encoder = joblib.load(f'models/{column}_label_encoder.pkl')\n",
    "    \n",
    "    df[column] = label_encoder.transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['CountryCode', 'State', 'City']\n",
    "scaled_data_new =df[columns_to_scale]\n",
    "pca = joblib.load('models/location.pkl')\n",
    "df['location'] = pca.transform(scaled_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['AccountSid', 'AccountUpn', 'AccountObjectId','AccountName']\n",
    "scaled_data_new =df[columns_to_scale]\n",
    "pca = joblib.load('models/Account.pkl')\n",
    "df['Account'] = pca.transform(scaled_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['RegistryValueName', 'RegistryValueData']\n",
    "scaled_data_new =df[columns_to_scale]\n",
    "pca = joblib.load('models/RegistryName.pkl')\n",
    "df['RegistryName'] = pca.transform(scaled_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['FileName','FolderPath','Sha256']\n",
    "scaled_data_new =df[columns_to_scale]\n",
    "pca = joblib.load('models/Path.pkl')\n",
    "df['Path'] = pca.transform(scaled_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['CountryCode', 'State', 'City','OSVersion','ApplicationName','AccountSid', 'AccountUpn','Sha256', 'AccountObjectId','AccountName','RegistryValueName', 'RegistryValueData','FileName','FolderPath'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048563"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = df.drop('IncidentGrade', axis=1) \n",
    "y_test = df['IncidentGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('models/scaler.pkl')\n",
    "X_test= scaler.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1.drop('IncidentGrade', axis=1) \n",
    "y_train = df1['IncidentGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5812697949479431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60    443490\n",
      "           1       0.40      0.42      0.41    228276\n",
      "           2       0.62      0.71      0.66    376797\n",
      "\n",
      "    accuracy                           0.58   1048563\n",
      "   macro avg       0.56      0.56      0.56   1048563\n",
      "weighted avg       0.58      0.58      0.58   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5747599333564125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59    443490\n",
      "           1       0.37      0.45      0.41    228276\n",
      "           2       0.65      0.67      0.66    376797\n",
      "\n",
      "    accuracy                           0.57   1048563\n",
      "   macro avg       0.56      0.56      0.56   1048563\n",
      "weighted avg       0.59      0.57      0.58   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_lda))\n",
    "print(classification_report(y_test, y_pred_lda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5706085375890624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59    443490\n",
      "           1       0.40      0.39      0.40    228276\n",
      "           2       0.59      0.72      0.65    376797\n",
      "\n",
      "    accuracy                           0.57   1048563\n",
      "   macro avg       0.55      0.55      0.54   1048563\n",
      "weighted avg       0.57      0.57      0.57   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge = RidgeClassifier()\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_ridge))\n",
    "print(classification_report(y_test, y_pred_ridge))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982912805429908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91    443490\n",
      "           1       0.83      0.84      0.83    228276\n",
      "           2       0.93      0.91      0.92    376797\n",
      "\n",
      "    accuracy                           0.90   1048563\n",
      "   macro avg       0.89      0.89      0.89   1048563\n",
      "weighted avg       0.90      0.90      0.90   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7284855559465668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75    443490\n",
      "           1       0.60      0.66      0.63    228276\n",
      "           2       0.83      0.72      0.77    376797\n",
      "\n",
      "    accuracy                           0.73   1048563\n",
      "   macro avg       0.72      0.72      0.72   1048563\n",
      "weighted avg       0.74      0.73      0.73   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_ada))\n",
    "print(classification_report(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8830818939825266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89    443490\n",
      "           1       0.76      0.89      0.82    228276\n",
      "           2       0.93      0.89      0.91    376797\n",
      "\n",
      "    accuracy                           0.88   1048563\n",
      "   macro avg       0.87      0.88      0.88   1048563\n",
      "weighted avg       0.89      0.88      0.88   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.270367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3039\n",
      "[LightGBM] [Info] Number of data points in the train set: 6095859, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "0.8675520688790278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88    443490\n",
      "           1       0.74      0.89      0.81    228276\n",
      "           2       0.93      0.86      0.90    376797\n",
      "\n",
      "    accuracy                           0.87   1048563\n",
      "   macro avg       0.86      0.87      0.86   1048563\n",
      "weighted avg       0.88      0.87      0.87   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_lgb))\n",
    "print(classification_report(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Test Set Accuracy: 0.9016205988576748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88    443490\n",
      "           1       0.74      0.89      0.81    228276\n",
      "           2       0.93      0.86      0.90    376797\n",
      "\n",
      "    accuracy                           0.87   1048563\n",
      "   macro avg       0.86      0.87      0.86   1048563\n",
      "weighted avg       0.88      0.87      0.87   1048563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  \n",
    "    'max_depth': [None, 5, 10, 20],               \n",
    "    'min_samples_split': [2, 5, 10],            \n",
    "    'min_samples_leaf': [1, 2, 4],               \n",
    "    'max_features': [None, 'sqrt', 'log2']      \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_decision_tree_model.pkl']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_estimator, 'best_decision_tree_model.pkl')\n",
    "\n",
    "# You can later load the model like this:\n",
    "# loaded_model = joblib.load('best_decision_tree_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
